---
title: "Human Activity Recognition"
author: "Anubhav Gupta"
date: "10/14/2021"
output: html_document
---

## Loading the dataset and packages

```{r message = FALSE}
pml_training <- read.csv(file = url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"))

pml_testing <- read.csv(file = url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"))


library(caret)
library(dplyr)

```

## Random subsampling

I used random subsampling for corss validation by partitioning the pml_training dataset into training dataset and testing dataset in the ratio 7:3.

```{r}

## Removing the first five columns of the data

pml_training <- pml_training[, -c(1:5)]

pml_testing <- pml_testing[, -c(1:5)]

## Partioning the sub_pml_Training data for cross validation

inTrain <- createDataPartition(y = pml_training$classe, p = 0.7, list = FALSE)

## This is the training data
training_data <- pml_training[inTrain, ]

## This is the testing data for cross validation
testing_data <- pml_training[-inTrain,]
```

## Removing NA values

I removed variables that contain *NA* values.

```{r}

which_col <- as.logical(colSums(is.na(training_data)) == 0)
training_data <- training_data[, which_col]

testing_data <- testing_data[, which_col]
testing_data$classe <- factor(testing_data$classe)

pml_testing <- pml_testing[, which_col]

```

## Removing zero covariates

Then, I removed zero covariates i.e. variables that have a lot of repeated entries.

```{r}
nzv <- nearZeroVar(training_data, saveMetrics = TRUE)
training_data <- training_data[, !nzv$nzv]

testing_data <- testing_data[, !nzv$nzv]

pml_testing <- pml_testing[, !nzv$nzv]

```


## Principal Component Analysis

I did the PCA so that I can reduce the number of predictors. 

```{r}
pca <- prcomp(training_data[,-54])

n <- 24
percent_dev <- sum(pca$sdev[1:n])/sum(pca$sdev)
percent_dev
```


## Preprocessing using the PCA

I chose the first 24 PCA components because it explained ~95% of the variance. In the next step, I used the preprocess function from the caret package.


```{r}
# preProc <- preProcess(training_data[,-54], method = "pca", pcaComp = n)
preProc <- readRDS(file = "preProc.RDS")

trainPC <- predict(preProc, training_data[,-54])
```

## Random forest model

I chose a random forest model because the response variables are categorical. I fitted the random forest model to the training data.

```{r}
# modelFit <- train(classe ~ ., method = "rf", data = trainPC, prox = TRUE)
modelFit <- readRDS("modelfit.RDS")
```


## Cross validation and out of sample error

I used the random forest model to cross validate on the testing data. The out of sample error is given below:

```{r}
test_PC <- predict(preProc, testing_data[,-54])
pred_data <- predict(modelFit, test_PC)

confusionMatrix(testing_data$classe, pred_data)
```

## Prediction on 20 cases

I used the random forest model to predict 20 different cases from the pml_testing dataset.

```{r}
pml_test_PC <- predict(preProc, pml_testing)
pml_pred_data <- predict(modelFit, pml_test_PC)
print(pml_pred_data)
```

